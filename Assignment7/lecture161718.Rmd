---
title: "Lecture161718"
author: "YujieWang"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Lecture 16

### Simulation1
```{r}
mu<-1 #choose a mean
sigma<-2 #choose a standard deviation

#1. generate some x indices
x<-seq(mu-3*sigma,mu+3*sigma,sigma*0.01)

#2. data frame with population density
df_gaussian<-data.frame(x,Density=dnorm(x,mean=mu,sd=sigma),Source="Population")

#3. plot the density function
df_gaussian %>% ggplot(aes(x=x,y=Density,color=Source))+
  geom_line()+ylab("Density function")+theme_bw()
```

```{r}
set.seed(123)
sample_size<-100

#4. generate a sample of Gaussian random variables
sample_data<-rnorm(sample_size,mu,sigma)

#5. ML estimate of mu and sigma
mu_mle<-mean(sample_data)
sigma_mle<-sd(sample_data)*sqrt((sample_size-1)/sample_size)

#6. add estimated density function to df
df_gaussian<-df_gaussian %>% 
  rbind(data.frame(x,Density=dnorm(x,mean=mu_mle,sd=sigma_mle),
                   Source="MLE estimate"))

#7. plot the true and estimated density functions
df_gaussian %>% ggplot(aes(x=x,y=Density,color=Source))+
  geom_line()+ylab("Density function")+theme_bw()
```

### Simulation2

```{r}
library(palmerpenguins)
```

```{r}
#1. sample of Gentoo weights
gentoo_weights<-penguins %>%
  filter(species=='Gentoo') %>%
  pull(body_mass_g) # extract the column of Gentoo weights

#2. ML estimates of mu and sigma
n<-length(gentoo_weights) #sample size
mu_mle<-mean(gentoo_weights,na.rm=TRUE) #mle mean
sigma_mle<-sd(gentoo_weights,na.rm=TRUE)*sqrt((n-1)/n) #mle standard deviation

```

```{r}
#4. generate indices
weights<-seq(mu_mle-3*sigma_mle,mu_mle+3*sigma_mle,sigma_mle*0.001)

#5.1 plot estimated density functions(MLE density)
colors<-c("MLE density"="red","Kernel density"="blue") #set color legend
estimated_density=data.frame(Weight=weights,
                             Density=dnorm(weights,mean=mu_mle,sd=sigma_mle))
plot_obj<-ggplot()+geom_line(data=estimated_density,
                             aes(x=Weight,y=Density,color="MLE density"))

#5.2 kernel density plot of the sample
plot_obj+geom_density(data=tibble(gentoo_weights),aes(x=gentoo_weights,color="Kernel density"))+
  labs(y="Density function",color="Estimator")+theme_bw()+scale_color_manual(values=colors)
```

### Simulation3


```{r}
set.seed(0)
sample_size<-100
theta_0<-5 #True parameter theta

#1. Generate sample of a sequence of Cauchy R.V.
cauchy_sample<-rcauchy(n=sample_size,location=theta_0)

#2. The log likelihood function
log_lik_cauchy<-function(theta,sample_X){return(-sum(log(1+(sample_X-theta)**2)))}
log_lik_cauchy_X<-function(theta){return(log_lik_cauchy(theta,cauchy_sample))}

#3. optimise the log likelihood function
theta_ml_est<-optimise(f=log_lik_cauchy_X,interval=c(-1000,1000),maximum=TRUE)$maximum
theta_ml_est
```

```{r}
set.seed(0)

num_trials<-100000
sample_size<-100
theta_0<-5 #True parameter theta

#1. log likelihood function
log_lik_cauchy<-function(theta,sample_X){return(-sum(log(1+(sample_X-theta)**2)))}

#2. mapping a sample to ML estimate of theta
theta_ml<-function(sample_X){
  log_lik_cauchy_X<-function(theta){return(log_lik_cauchy(theta,sample_X))}
  theta_ml_est<-optimise(f=log_lik_cauchy_X,interval=c(-10,18),maximum=TRUE)$maximum
  return(theta_ml_est)
}

#3.1 create num_trials samples; the size of each sample is sample_size
df<-data.frame(trial=seq(num_trials))%>%
  mutate(sample=map(.x=trial,~rcauchy(sample_size,location=theta_0)))

#3.2 for each sample,compute ML est and Median est
cauchy_simulation_df<-mutate(df,ml_est=map_dbl(.x=sample,.f=theta_ml))%>%
  mutate(med_est=map_dbl(.x=sample,.f=median))


#4. pivot
plot_df<-cauchy_simulation_df%>%
  pivot_longer(cols=c(ml_est,med_est))%>%
  mutate(name=map_chr(.x=name,~case_when(.x=="med_est"~"Median",
                                         .x=="ml_est"~"Maximum likelihood")))

#5. create plot
ggplot(plot_df,mapping=aes(x=value,color=name,linetype=name))+
  geom_density()+theme_bw()+xlim(c(4,6))+
  labs(color="",linetype="")+xlab("Estimate")+ylab("Density")

```
```{r}
msefunc<-function(x){return(mean((x-theta_0)^2))}

med_estimate_mean_sqr_error<-cauchy_simulation_df%>%
  pull(med_est) %>% msefunc

med_estimate_mean_sqr_error
```

```{r}
ml_estimate_mean_sqr_error<-cauchy_simulation_df%>%
  pull(ml_est)%>% msefunc

ml_estimate_mean_sqr_error
```

## Lecture 17

### compute t
```{r}
#compute t_{alpha/2,n-1}
alpha<-0.05
n<-80
t=qt(1-alpha/2,df=n-1) #quantile function for t distribution
t
```
```{r}
library(ggplot2)
library(palmerpenguins)
library(tidyverse)
penguins%>%head(10)
```


```{r}
ggplot(data=filter(penguins,species=="Adelie"),
       aes(x=flipper_length_mm))+
  geom_density()+theme_bw()+
  xlab("Flipper length(mm)")
```
```{r}
ggplot(data=filter(penguins,species=="Adelie"),
       aes(sample=flipper_length_mm))+
  theme_bw()+stat_qq()+stat_qq_line(color="blue")
```
### Binomial proportion confidence interval
```{r}
library(PropCIs)
```

```{r}
driving_test_results<-c(1,0,1,0,0,0,0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,0,1,0)
mean(driving_test_results)
```

```{r}
alpha<-0.05
num_successes<-sum(driving_test_results)#total passes
sample_size<-length(driving_test_results) #sample size
scoreci(x=num_successes,n=sample_size,conf.level = 1-alpha)
```

### The Bootstrap method:example

```{r}
library(boot) #load the library
```

```{r}
set.seed(123) #set random seed
geyser=faithful #the volcano data set
```

```{r}
#1. define a function which computes the median of a column of interest
compute_median<-function(df,indicies,col_name){
  sub_sample<-slice(df,indicies)%>% pull(all_of(col_name)) #extract subsample
  return(median(sub_sample,na.rm=TRUE)) #reutrn median
}
```

```{r}
#2. use the boot function to generate the bootstrap statistics
results<-boot(data=geyser,statistic=compute_median,col_name="eruptions",R=10000)

#3. compute the 99% confidence interval for the median
boot.ci(boot.out = results,type="basic",conf=0.99)
```

## Lecture 18

### One sample t-test
```{r}
#sample_size<-length(salt_vect) #sample size
#sample_mean<-mean(salt_vect) #sample mean
#sample_sd<-sd(salt_vect) #standard deviation
sample_size<-30
sample_mean<-989.06
sample_sd<-19.62
test_statistic<-(sample_mean-1000)/(sample_sd/sqrt(sample_size)) # test statistic
test_statistic
```

```{r}
2*(1-pt(abs(test_statistic),df=sample_size-1))
```


```{r}
tibble(salt_vect)%>% ggplot(aes(x=salt_vect))+geom_density()+
  theme_bw()+labs(x="weight (grams)",y="density")
```

```{r}
tibble(salt_vect)%>%
  ggplot(aes(sample=salt_vect))+stat_qq()+stat_qq_line(color="blue")+theme_bw()
```

```{r}
t.test(x=salt_vect,mu=1000)
```

```{r}
alpha<-0.05 #95%-level confidence intervals
sample_size<-length(salt_vect) # sample size
sample_mean<-mean(salt_vect) # sample mean
sample_sd<-sd(salt_vect) # sample deviation
t<-qt(1-alpha/2,df=sample_size-1) # (1-alpha/2)-quantile
confidence_interval_l<-sample_mean-t*sample_sd/sqrt(sample_size) #lower confidence bound
confidence_interval_u<-sample_mean+t*sample_sd/sqrt(sample_size)# upper confidence bound
confidence_interval<-c(confidence_interval_l,confidence_interval_u) #confidence interval
confidence_interval
```


### one-sample t-test example
```{r}
tibble(chicken_weights)%>%
  ggplot(aes(x=chicken_weights))+geom_density()+
  theme_bw()+labs(x="weight (grams)",y="density")
```

```{r}
tibble(chicken_weights)%>%
  ggplot(aes(sample=chicken_weights))+stat_qq()+stat_qq_line(color="blue")+theme_bw()
```

```{r}
t.test(x=salt_vect,mu=1000,alternative="two.sided")

```

### The Binomial test
```{r}
correct_or_incorrect=c(0,1,0,1,1,0,1,1,1,0)
correct_or_incorrect
```
```{r}
sample_size<-length(correct_or_incorrect)
num_successes<-sum(correct_or_incorrect)
binom.test(x=num_successes,n=sample_size,p=1/6,alternative="two.sided")
```


