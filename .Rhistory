mutate(reds=map_dbl(.x=samples,~compute_num(.x,1,50)),
blues=map_dbl(.x=samples,~compute_num(.x,51,80)),
greens=map_dbl(.x=samples,~compute_num(.x,81,100)))
sampling_without_replacement_simulation%>%head(10)
sample_head<-sampling_without_replacement_simulation%>%head(10)
pmin(sample_head$reds,sample_head$blues,sample_head$greens)
min(sample_head$reds,sample_head$blues,sample_head$greens)
min_color<-pmin(sampling_without_replacement_simulation$reds,
sampling_without_replacement_simulation$blues,
sampling_without_replacement_simulation$greens)
## Estimated Probability
prob_zero<-sum(min_color==0)/number_trials
prob_zero
num_sum<-function(){
num<-0
for (i in 1:10){
num=num+(choose(30,i)*choose(20,10-i)+choose(20,i)*choose(50,10-i)+choose(50,i)*choose(30,10-i))
}
return(num)
}
#Theoretical Probability
PA<-num_sum()/choose(100,10)
PA
## Simulative Probability
set.seed(0)
PS<-function(num_trials){
sample_size<-10
sampling_without_replacement_simulation<-data.frame(trials=1:number_trials)%>%
mutate(samples=map(.x=trials,~sample(100,10,replace=FALSE)))
sampling_without_replacement_simulation<-sampling_without_replacement_simulation%>%
mutate(reds=map_dbl(.x=samples,~compute_num(.x,1,50)),
blues=map_dbl(.x=samples,~compute_num(.x,51,80)),
greens=map_dbl(.x=samples,~compute_num(.x,81,100)))
min_color<-pmin(sampling_without_replacement_simulation$reds,
sampling_without_replacement_simulation$blues,
sampling_without_replacement_simulation$greens)
prob_zero<-sum(min_color==0)/number_trials
return(prob_zero)
}
PSline<-map_dbl(seq(10,10000,by=100),PS)
num_trial<-seq(10,10000,by=100)
Table<-data.frame(num_trial,PSline)
ggplot(data=Table,aes(x=num_trial,y=PSline))+
geom_line()+
xlab("Number of trials")+
ylab("EstimateProbability")+
geom_hline(aes(yintercept=PA),color="red",linetype="dashed")
ggplot(prob_by_num_reds, aes(x=num_reds, y=prob)) + geom_line() + xlab('Number of reds') + ylab('Probability') + theme_bw()
num1 <- choose(50,10) + choose(70,10) + choose(80,10) -
choose(20,10) - choose(30,10) - choose(50,10)
num2 <- choose(100,10)
probs_A <- num1/num2
print(probs_A)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
rmultinom(2, 7, prob=c(0.5, 0.2, 0.3))
samples_Xi<-rmultinom(50000,3,prob=c(0.5,0.2,0.3))
tem_Y<-matrix(c(0,3,10),nrow=1)
samples_Y<-data.frame(Y=t(tem_Y%*%samples_Xi))
samples_Y%>%head(10)
ggplot(data=samples_Y,aes(x=Y))+geom_bar()
samples_Xi<-rmultinom(50000,20,prob=c(0.5,0.2,0.3))
samples_Y<-data.frame(Y=t(tem_Y%*%samples_Xi))
samples_Y%>%head(10)
ggplot(data=samples_Y,aes(x=Y))+geom_bar()
samples_Xi<-rmultinom(50000,2000,prob=c(0.5,0.2,0.3))
samples_Y<-data.frame(Y=t(tem_Y%*%samples_Xi))
samples_Y%>%head(10)
ggplot(data=samples_Y,aes(x=Y))+geom_bar()
ggplot(data=samples_Y,aes(x=Y))+geom_bar()+theme_bw()
samples_Xi<-rmultinom(50000,3,prob=c(0.5,0.2,0.3))
tem_Y<-matrix(c(0,3,10),nrow=1)
samples_Y<-data.frame(Y=t(tem_Y%*%samples_Xi))
samples_Y%>%head(10)
ggplot(data=samples_Y,aes(x=Y))+geom_bar()+theme_bw()
samples_Xi<-rmultinom(50000,20,prob=c(0.5,0.2,0.3))
samples_Y<-data.frame(Y=t(tem_Y%*%samples_Xi))
samples_Y%>%head(10)
ggplot(data=samples_Y,aes(x=Y))+geom_bar()+theme_bw()
print(range(samples_Y))
print(diff(range(samples_Y)))
samples_Y<-data.frame(Y=t(tem_Y%*%samples_Xi))
samples_Y%>%head(10)
samples_Xi<-rmultinom(50000,2000,prob=c(0.5,0.2,0.3))
samples_Y<-data.frame(Y=t(tem_Y%*%samples_Xi))
samples_Y%>%head(10)
ggplot(data=samples_Y,aes(x=Y))+geom_bar()+theme_bw()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
num_trials<-1000000 #set the number of trials
set.seed(0) #set the random seed
sample_size<-2 # set the sample size
sigma<-12/35
mu<-7/2
# simulate the sample average of a dice roll:
# add columns dice_sample(1...6) and sample_avg(sample average)
dice_sample_average_simulation<-data.frame(trial=1:num_trials)%>%
mutate(dice_sample=map(.x=trial,~sample(6,sample_size,replace=TRUE)))%>%
mutate(sample_avg=map_dbl(.x=dice_sample,~(mean(.x))))
print(dice_sample_average_simulation)
# plot a histogram to display the results
dice_sample_average_simulation%>%
ggplot(aes(x=sample_avg))+
geom_histogram(aes(y=..count../sum(..count..)),
binwidth=1/sample_size,fill="blue",color="blue")+
theme_bw()+xlim(c(-3,3))+
xlab("Sample average")+ylab("Proportion")
set.seed(0)
num_trials<-1000
sample_size<-30
q<-0.3 #True parameter q
#1. create data-frame (trial=1,2,...,num_trials)
df<-data.frame(trial=seq(num_trials))
#2. generate samples for sequences of Bernoulli random variables
df<-mutate(df,simulation=map(.x=trial,.f=~rbinom(sample_size,1,q)))
#3. Compute the sample mean
simulation_df<-mutate(df,sample_mean=map_dbl(.x=simulation,.f=mean))
#4.1 kernel density plot of sample means
plot_obj<-ggplot()+labs(x="Mean",y="Density")+theme_bw()+
geom_density(data=simulation_df,aes(x=sample_mean,color="Sample",linetype="Sample"))
#4.2 vertical line displaying population mean
plot_obj<-plot_obj+geom_vline(aes(xintercept=q,color="Population",linetype="Population"))
#4.3 legends
plot_obj+scale_color_manual(name="legend",values=c("Sample"="red","Population"="blue"))+
scale_linetype_manual(name="Legend",values=c("Sample"="solid","Population"="dashed"))
# A sequence of samples with sizes varying from 1 and 10000
set.seed(0)
num_trials_per_sample_size<-10
max_sample_size<-10000
q<-0.3 #True parameter q
#1. create a data frame containing all pairs of sample_size and trial
df<-crossing(trial=seq(num_trials_per_sample_size),
sample_size=seq(to=sqrt(max_sample_size),by=0.1)**2)
#2. For each pair,simulate a sequence of Bernoulli random variables
df<-mutate(df,simulation=pmap(.l=list(trial,sample_size),.f=~rbinom(.y,1,q)))
#3. compute the sample mean of each sequence
sim_by_n_df<-mutate(df,sample_mean=map_dbl(.x=simulation,.f=mean))
#4.1 scatter plot of sample means (for different sample sizes)
plot_obj<-ggplot()+labs(x="Sample size",y="Mean")+theme_bw()+
geom_point(data=sim_by_n_df,
aes(x=sample_size,y=sample_mean,color="Sample",linetype="Sample"),
size=0.1)
#4.2 horizontal line displaying population mean
plot_obj<-plot_obj+
geom_hline(aes(yintercept=q,color="Population",linetype="Population"),size=1)
#4.3 add legends
plot_obj+scale_color_manual(name="Legend",values=c("Sample"="blue","Population"="red"))+
scale_linetype_manual(name="Legend",values=c("Sample"="dashed","Population"="solid"))+
scale_x_sqrt()
set.seed(0)
num_trials<-1000
sample_size<-30
mu <- 1 #True mu
sigma_sqr <- 3  #True sigma^2
#1. Create a data frame (trial=1,2,...,num_trials)
df<- data.frame(trial=seq(num_trials))
#2. generate num_trials sample with rnorm()
df<- mutate(df,simulation=map(.x=trial,
.f=~rnorm(sample_size,mean=mu,sd=sqrt(sigma_sqr))))
#3. compute the sample variance (estimate sigma^2)
simulation_df<- mutate(df,sample_var=map_dbl(.x=simulation,.f=var))
#4.1 kernel density plot of sample variance
plot_obj<- ggplot()+labs(x="Variance",y="Density")+theme_bw()+
geom_density(data=simulation_df,aes(x=sample_var,color="Sample",linetype="Sample"))
#4.2 vertical line displaying population mean
plot_obj<- plot_obj+geom_vline(aes(xintercept=sigma_sqr,
color="Population",linetype="Population"))
#4.3 add legend
plot_obj+scale_color_manual(name="Legend",
values=c("Sample"="red","Population"="blue"))+
scale_linetype_manual(name="Legend",
values=c("Sample"="solid","Population"="dashed"))
set.seed(0)
num_trials_per_sample_size<-10
max_sample_size<-10000
mu <- 1 #True mu
sigma_sqr <- 3  # sigma^2
#1. create data frame of all pairs of sample_size and trial
df<-crossing(trial=seq(num_trials_per_sample_size),
sample_size=seq(to=sqrt(max_sample_size),by=0.1)**2)
#2. For each pair,simulate a sequence of Gaussian random variables
df<-mutate(df,simulation=pmap(.l=list(trial,sample_size),
.f=~rnorm(.y,mean=mu,sd=sqrt(sigma_sqr))))
#3. For each sequence, compute the sample variance
sim_by_n_df<-mutate(df,sample_var=map_dbl(.x=simulation,.f=var))
#4.1 create a scatter plot of sample variance
plot_obj<-ggplot()+labs(x="Sample size",y="Variance")+theme_bw()+
geom_point(data=sim_by_n_df,
aes(x=sample_size,y=sample_var,color="Sample",
linetype="Sample"),size=0.1)
#4.2 add a horizontal line displaying population variance
plot_obj<-plot_obj+geom_hline(aes(yintercept=sigma_sqr,color="Population",
linetype="Population"),size=1)
#4.3 add Legends
plot_obj+
scale_color_manual(name="Legend",values=c("Sample"="blue","Population"="red"))+
scale_linetype_manual(name="Legend",values=c("Sample"="dashed","Population"="solid"))+
scale_x_sqrt()
set.seed(0)
num_trials_per_sample_size<-10
max_sample_size<-10000
theta<-1 #True parameter theta
#1. create data frame consisting of all pairs of sample_size and trial
df<-crossing(trial=seq(num_trials_per_sample_size),
sample_size=seq(to=sqrt(max_sample_size),by=0.1)**2)
#2. for each pair,simulate a sequence of Cauchy random variables
df<-mutate(df,simulation=pmap(.l=list(trial,sample_size),
.f=~rcauchy(.y,location=theta)))
#3. for each sequence,compute its sample mean
sim_by_n_df<-mutate(df,sample_mean=map_dbl(.x=simulation,.f=mean))
#4.1 create a scatter plot of sample variance
plot_obj<-ggplot()+labs(x="Sample size",y="Sample mean")+theme_bw()+
geom_point(data=sim_by_n_df,
aes(x=sample_size,y=sample_mean,color="Sample",
linetype="Sample"),size=0.1)+ylim(-10,10)
#4.2 add a horizontal line displaying population variance
plot_obj<-plot_obj+geom_hline(aes(yintercept=theta,color="Theta",
linetype="Theta"),size=1)
#4.3 add Legends
plot_obj+
scale_color_manual(name="Legend",values=c("Sample"="blue","Theta"="red"))+
scale_linetype_manual(name="Legend",values=c("Sample"="dashed","Theta"="solid"))+
scale_x_sqrt()
set.seed(0)
num_trials_per_sample_size<-10
max_sample_size<-10000
theta<-1 #True parameter theta
#1. create data frame consisting of all pairs of sample_size and trial
df<-crossing(trial=seq(num_trials_per_sample_size),
sample_size=seq(to=sqrt(max_sample_size),by=0.1)**2)
#2. for each pair,simulate a sequence of Cauchy random variables
df<-mutate(df,simulation=pmap(.l=list(trial,sample_size),
.f=~rcauchy(.y,location=theta)))
#3. for each sequence,compute its sample median
sim_by_n_df<-mutate(df,sample_median=map_dbl(.x=simulation,.f=median))
#4.1 create a scatter plot of sample variance
plot_obj<-ggplot()+labs(x="Sample size",y="Sample median")+theme_bw()+
geom_point(data=sim_by_n_df,
aes(x=sample_size,y=sample_median,color="Sample",
linetype="Sample"),size=0.1)+ylim(-10,10)
#4.2 add a horizontal line displaying population variance
plot_obj<-plot_obj+geom_hline(aes(yintercept=theta,color="Theta",
linetype="Theta"),size=1)
#4.3 add Legends
plot_obj+
scale_color_manual(name="Legend",values=c("Sample"="blue","Theta"="red"))+
scale_linetype_manual(name="Legend",values=c("Sample"="dashed","Theta"="solid"))+
scale_x_sqrt()
knitr::opts_chunk$set(echo = TRUE)
mu<-1 #choose a mean
sigma<-2 #choose a standard deviation
#1. generate some x indices
x<-seq(mu-3*sigma,mu+3*sigma,sigma*0.01)
#2. data frame with population density
df_gaussian<-data.frame(x,Density=dnorm(x,mean=mu,sd=sigma),Source="Population")
#3. plot the density function
df_gaussian %>% ggplot(aes(x=x,y=Density,color=Source))+
geom_line()+ylab("Density function")+theme_bw()
set.seed(123)
sample_size<-100
#4. generate a sample of Gaussian random variables
sample_data<-rnorm(sample_size,mu,sigma)
#5. ML estimate of mu and sigma
mu_mle<-mean(sample_data)
sigma_mle<-sd(sample_data)*sqrt((sample_size-1)/sample_size)
#6. add estimated density function to df
df_gaussian<-df_gaussian %>%
rbind(data.frame(x,Density=dnorm(x,mean=mu_mle,sd=sigma_mle),
Source="MLE estimate"))
#7. plot the true and estimated density functions
df_gaussian %>% ggplot(aes(x=x,y=Density,color=Source))+
geom_line()+ylab("Density function")+theme_bw()
library(palmerpenguins)
#1. sample of Gentoo weights
gentoo_weights<-penguins %>%
filter(species=='Gentoo') %>%
pull(body_mass_g) # extract the column of Gentoo weights
#2. ML estimates of mu and sigma
n<-length(gentoo_weights) #sample size
mu_mle<-mean(gentoo_weights,na.rm=TRUE) #mle mean
sigma_mle<-sd(gentoo_weights,na.rm=TRUE)*sqrt((n-1)/n) #mle standard deviation
#4. generate indices
weights<-seq(mu_mle-3*sigma_mle,mu_mle+3*sigma_mle,sigma_mle*0.001)
#5.1 plot estimated density functions(MLE density)
colors<-c("MLE density"="red","Kernel density"="blue") #set color legend
estimated_density=data.frame(Weight=weights,
Density=dnorm(weights,mean=mu_mle,sd=sigma_mle))
plot_obj<-ggplot()+geom_line(data=estimated_density,
aes(x=Weight,y=Density,color="MLE density"))
#5.2 kernel density plot of the sample
plot_obj+geom_density(data=tibble(gentoo_weights),aes(x=gentoo_weights,color="Kernel density"))+
labs(y="Density function",color="Estimator")+theme_bw()+scale_color_manual(values=colors)
set.seed(0)
sample_size<-100
theta_0<-5 #True parameter theta
#1. Generate sample of a sequence of Cauchy R.V.
cauchy_sample<-rcauchy(n=sample_size,location=theta_0)
#2. The log likelihood function
log_lik_cauchy<-function(theta,sample_X){return(-sum(log(1+(sample_X-theta)**2)))}
log_lik_cauchy_X<-function(theta){return(log_lik_cauchy(theta,cauchy_sample))}
#3. optimise the log likelihood function
theta_ml_est<-optimise(f=log_lik_cauchy_X,interval=c(-1000,1000),maximum=TRUE)$maximum
theta_ml_est
set.seed(0)
num_trials<-100000
sample_size<-100
theta_0<-5 #True parameter theta
#1. log likelihood function
log_lik_cauchy<-function(theta,sample_X){return(-sum(log(1+(sample_X-theta)**2)))}
#2. mapping a sample to ML estimate of theta
theta_ml<-function(sample_X){
log_lik_cauchy_X<-function(theta){return(log_lik_cauchy(theta,sample_X))}
theta_ml_est<-optimise(f=log_lik_cauchy_X,interval=c(-10,18),maximum=TRUE)$maximum
return(theta_ml_est)
}
#3.1 create num_trials samples; the size of each sample is sample_size
df<-data.frame(trial=seq(num_trials))%>%
mutate(sample=map(.x=trial,~rcauchy(sample_size,location=theta_0)))
#3.2 for each sample,compute ML est and Median est
cauchy_simulation_df<-mutate(df,ml_est=map_dbl(.x=sample,.f=theta_ml))%>%
mutate(med_est=map_dbl(.x=sample,.f=median))
#4. pivot
plot_df<-cauchy_simulation_df%>%
pivot_longer(cols=c(ml_est,med_est))%>%
mutate(name=map_chr(.x=name,~case_when(.x=="med_est"~"Median",
.x=="ml_est"~"Maximum likelihood")))
#5. create plot
ggplot(plot_df,mapping=aes(x=value,color=name,linetype=name))+
geom_density()+theme_bw()+xlim(c(4,6))+
labs(color="",linetype="")+xlab("Estimate")+ylab("Density")
msefunc<-function(x){return(mean((x-theta_0)^2))}
med_estimate_mean_sqr_error<-cauchy_simulation_df%>%
pull(med_est) %>% msefunc
med_estimate_mean_sqr_error
ml_estimate_mean_sqr_error<-cauchy_simulation_df%>%
pull(ml_est)%>% msefunc
ml_estimate_mean_sqr_error
#compute t_{alpha/2,n-1}
alpha<-0.05
n<-80
t=qt(1-alpha/2,df=n-1) #quantile function for t distribution
t
library(ggplot2)
library(palmerpenguins)
library(tidyverse)
penguins%>%head(10)
ggplot(data=filter(penguins,species=="Adelie"),
aes(x=flipper_length_mm))+
geom_density()+theme_bw()+
xlab("Flipper length(mm)")
ggplot(data=filter(penguins,species=="Adelie"),
aes(sample=flipper_length_mm))+
theme_bw()+stat_qq()+stat_qq_line(color="blue")
library(PropCIs)
driving_test_results<-c(1,0,1,0,0,0,0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,0,1,0)
mean(driving_test_results)
alpha<-0.05
num_successes<-sum(driving_test_results)#total passes
sample_size<-length(driving_test_results) #sample size
scoreci(x=num_successes,n=sample_size,conf.level = 1-alpha)
library(boot) #load the library
set.seed(123) #set random seed
geyser=faithful #the volcano data set
#1. define a function which computes the median of a column of interest
compute_median<-function(df,indicies,col_name){
sub_sample<-slice(df,indicies)%>% pull(all_of(col_name)) #extract subsample
return(median(sub_sample,na.rm=TRUE)) #reutrn median
}
#2. use the boot function to generate the bootstrap statistics
results<-boot(data=geyser,statistic=compute_median,col_name="eruptions",R=10000)
#3. compute the 99% confidence interval for the median
boot.ci(boot.out = results,type="basic",conf=0.99)
#sample_size<-length(salt_vect) #sample size
#sample_mean<-mean(salt_vect) #sample mean
#sample_sd<-sd(salt_vect) #standard deviation
sample_size<-30
sample_mean<-989.06
sample_sd<-19.62
test_statistic<-(sample_mean-1000)/(sample_sd/sqrt(sample_size)) # test statistic
test_statistic
2*(1-pt(abs(test_statistic),df=sample_size-1))
tibble(salt_vect)%>% ggplot(aes(x=salt_vect))+geom_density()+
theme_bw()+labs(x="weight (grams)",y="density")
s<-list(name="Yujie",number="221755",age="22")
class(s)<-"student"
s
student<-function(n,a,g){
if(g>3||g<0) stop("GPA must be between 0 and 4")
value<-list(name=n,age=a,GPA=g)
attr(value,"class")<-"student"
value
}
s<-student("Yujie",22,3)
s
setClass("student",slots=list(name="character",age="numeric",GPA="numeric"))
s<-new("student",name="John",age=21,GPA=3.5)
s
s@name
s@age
s@GPA
s@GPA<-3.7
s
slot(s,"age")<-30
s@age
setMethod("show","student",
function(object){
cat(object@name,"\n")
cat(object@age,"years old\n")
cat("GPA:",object@GPA,"\n")
}
)
s<-new("student",name="John",age=21,GPA=3.5)
s
n<-floor(rnorm(10000,500,100))
t<-table(n)
barplot(t)
n<-floor(rnorm(10000,500,100))
n
barplot(table(floor(rnorm(10000,500,100))),xlab="Numbers",ylab="Frequences")
typeof(5L)
typeof(5i)
typeof(5)
x<-3
y<-14
x+y
x-y
x*y
y/x
y%%x
y%/%x
y^x
x<-c(10,2,5)
x
y<-c(6,4,1)
y
x+y
x>y
x<-c(2,1,8,3)
y<-c(9,4) #Element of y is recycled to 9,4,9,4
x+y
x-1
x+c(1,2,3)
x<- -5
y<-if(x>0) 5 else 6
y
a=c(5,7,2,9)
ifelse(a%%2==0,"even","odd")
x <- c(TRUE,FALSE,0,6)
y <- c(FALSE,TRUE,FALSE,TRUE)
x&y
x&&y
x&&y
x<-c(2,5,3,9,8,11,6)
count<-0
for(val in x){
if(val%%2==0) count=count+1
}
count
x<-1:5
for(val in x){
if(val==3){
next
}
print(val)
}
x<-1
repeat{
print(x)
x=x+1
if(x==6){
break
}
}
pow<-function(x,y){
result<-x^y
print(paste(x,"raised to the power",y,"is",result))
}
pow(8,2)
pow(2,8)
pow(8,2)
pow(x=8,y=2)
pow(y=2,x=8)
pow(x=8,2)
pow(2,x=8)
pow(3,3)
pow<-function(x,y=2){
result<-x^y
print(paste(x,"raised to the power",y,"is",result))
}
pow(3)
pow(3,1)
outer_func<-function(){
inner_func<-function(){
a<<-30
print(a)
}
inner_func()
print(a)
}
outer_func()
print(a)
recursive.factorial<-function(x){
if(x==0) return(1)
else return (x*recursive.factorial(x-1))
}
recursive.factorial(3)
'%divisible%'<-function(x,y){
if(x%%y==0) return(TRUE)
else return (FALSE)
}
10%divisible%3
