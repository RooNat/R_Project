---
tags: R Coursework
---

## B.1
In this question, we consider <font color=#c10b26>the lifetime of products from a light bulb factory</font>. The factory has <font color=#c10b26>two LED bulb production lines</font> (==Line A and Line B==) that independently produce light bulbs.The light bulbs, however, are not always of high quality, and the products from <font color=#c10b26>Line A and Line B have different lifetimes.</font>

1. For a light bulb produced by <font color=#c10b26>Line A</font>, the probability that its lifetime is equal to or bigger than 2 years is $p_A$ (a number in $[0, 1]$). 
2. A light bulb from <font color=#c10b26>Line B generally has a shorter lifetime</font>, and the probability of its <font color=#c10b26>lifetime being equal to or bigger than</font> <font color=#c10b26>2 years</font> is $p_B$ (which is less than $p_A$)

The light bulbs produced from Line A and Line B are considered to be the same products by the factory and they are sold randomly to the customers. These light bulbs are sold in the same packages such that, given a light bulb, a customer can not identify which of the two production lines the light bulb is made from. Suppose that if we buy a light bulb produced by the factory, then it must come from either Line A or Line B,
1. and the probability that it comes from Line A is $p$. 
2. A customer bought a light bulb whose lifetime was unfortunately less than 2 years. The customer suspects that this light bulb was made in Line B.
	1. Let $\alpha$ denote the probability that this light bulb was made in Line B, given that its lifetime is less than 2 years. Derive a mathematical expression for $\alpha$ in terms of $p_A$, $p_B$ and $p$.
		$$P(bulb \: made \: in \: Line\:B| the \:lifetime\:is\:less\:than\:2\:years)=\dfrac{(1-p_B)\cdot (1-p)}{(1-p_A)\cdot p +(1-p_B)\cdot(1-p)}$$
	2. Suppose that $p_A$ = 0.99, $p_B$ = 0.5 and $p$ = 0.1. What is the numerical value of $\alpha$?
		$$\alpha=\dfrac{0.5\times 0.9}{0.01\times0.1+0.5\times 0.9}=0.9977$$
	Next, fix $p_A$ = 0.99, $p_B$ = 0.5 and $p$ = 0.1. Conduct <font color=#c10b26>a simulation study</font> to estimate the conditional probability $\alpha$ with samples.

	3. Your <font color=#c10b26>simulation study</font> should contain ==100000 trials==. In each of the trials, generate a sample of a light bulb. Each sample is represented by a pair of randomly generated numbers called $(Line, LessThan2Years )$:
		1. The random number $Line$ represents the product line that the light bulb was made from (with $Line=0$ representing $\text{Line A}$ and $\text{Line=1}$ representing $\text{Line B}$). The probability of $Line=0$ should be equal to $p$.
		2. The random number $LessThan2Years$ should be either $0$ or $1$, where $LessThan2Years=0$ represents that the lifetime of this bulb is not less than 2 years, and $LessThan2Years=1$ represents that the lifetime is less than 2 years. The number $LessThan2Years$ should be generated by taking into account the value of Line. If $Line =0$, then the probability of $LessThan2Years=0$ is equal to $p_A$. If $Line =1$, then the probability of $LessThan2Years=0$ is equal to $p_B$.
	4. Based on the samples generated in the simulation study, compute an estimate of the conditional probability $\alpha$. 
		1. First, select the subset of samples in which $LessThan2Years$ =1. 
		2. Second, within this subset of samples, compute the number of samples in which $Line =1$, and divide it by the total number of samples within this subset to get an estimate of the conditional probability $\alpha$. Display your estimate to at least 5 decimal places.

## B.2
In this question, we will explore statistical estimation for <font color=#c10b26>parameters</font> in <font color=#c10b26>continuous random variables</font>.

1. Suppose a product is being sold in a supermarket. 
2. We are interested in knowing how quickly the product returns to the shelf again after it is sold out. 
3. Let $X$ be a <font color=#c10b26>continuous random variable</font> denoting the length of time between <font color=#c10b26>the time point at which it is sold out</font> and <font color=#c10b26>the time point at which it is placed on the shelf again</font>. So $X$ should be a non-negative number, and $X = 0$ means that the product gets on the shelf immediately after it is sold out. Here, we assume that the probability density function of $X$ is given by
		$$p_\lambda(x)=\begin{cases}
		ae^{-\lambda (x-b)} \quad & \text{if } x\geq b,\\
		0 \quad & \text{if } x< b,
		\end{cases}$$
	where $b > 0$ is a known constant, $\lambda > 0$ is a parameter of the distribution, and $a$ is to be determined by $\lambda$ and $b$.
	1. First, determine the value of $a$: derive a mathematical expression of $a$ in terms of $\lambda$ and $b$.
		$$\begin{aligned}
		\int_{-\infty}^b0 \mathrm{d}x+\int_{b}^{+\infty}ae^{-\lambda(x-b)} &=1 \\
		[-\dfrac{a}{\lambda}e^{-\lambda(x-b)}]^{+\infty}_b&=1\\
		0-[-\dfrac{a}{\lambda}] &=1 \\
		a&=\lambda
	\end{aligned}$$
	
	2. Derive a formula for the ==population mean== and ==stand deviation== of the exponential random variable $X$ with parameter $\lambda$.
		**Population mean:**
		$$\begin{aligned}
		\text{E}(X) &=\int_{-\infty}^{+\infty} xp_{\lambda}(x)\mathrm{d}x\\
		&=\int_{b}^{+ \infty} x \lambda \cdot e^{-\lambda(x-b)}\mathrm{d}x \\
		&=[(-\dfrac{1}{\lambda}-x)e^{-\lambda(x-b)}]_{b}^{+\infty} \\
		&=[-xe^{-\lambda(x-b)}]_{b}^{+\infty}+[-\dfrac{1}{\lambda}e^{-\lambda (x-b)}]_{b}^{+ \infty} \\
		&=b+\dfrac{1}{\lambda}
		\end{aligned}$$
		
		**Stand deviation:**
		$$\begin{aligned}
		\sigma(x) &=\sqrt{\mathrm{Var}(x)} \\
		&=\sqrt{\mathrm{E}(X^2)-\mathrm{E}(X)^2} \\
		\end{aligned}$$
		$$\begin{aligned}
		\mathrm{E}(X^2) &=\int_{b}^{+ \infty}x^2p_{\lambda}(x) \mathrm{d}x	\\
		&= \int_{b}^{+ \infty} x^2 \cdot \lambda e^{-\lambda(x-b)}\mathrm{d}x \\
		&=[-x^2e^{-\lambda (x-b)}]_{b}^{+ \infty}+2\int_{b}^{+\infty}xe^{-\lambda (x-b)}\mathrm{d}x \\
		&=b^2+	\dfrac{2}{\lambda}\int_{b}^{+\infty} \lambda xe^{-\lambda(x-b)}\\
		&=b^2+\dfrac{2}{\lambda}\cdot \mathrm{E}(X)\\
		&=b^2+\dfrac{2}{\lambda}\cdot (\dfrac{1}{\lambda}+b) \\
		&=b^2+\dfrac{2}{\lambda ^2}+\dfrac{2b}{\lambda}
		\end{aligned}$$
		$$\begin{aligned}
		\text{So} \quad \sigma(x) &=\sqrt{b^2+\dfrac{2}{\lambda ^2}+\dfrac{2b}{\lambda}-(b+\dfrac{1}{\lambda})^2} \\
		&=\sqrt{\dfrac{1}{\lambda ^2}}\\
		&=\dfrac{1}{\lambda}
		\end{aligned}$$
		
	3. Derive a formula for the ==cumulative distribution function== and ==the quantile function== for the exponential random variable $X$ with parameter $\lambda$.
		The **cumulative distribution function** is:
		$$\begin{aligned}
		F_X(x)=\int_{-\infty}^{x}p_{\lambda}(x)\mathrm{d}x=[-e^{-\lambda (x-b)}]_{b}^{x}=1-e^{-\lambda (x-b)}
		\end{aligned}$$
		for $x \geq b$, and $F_X(x)=0$ for $x<b$
		
		The **quantile function** is $F_X^{-1}(p)=\mathrm{inf}\{x\in \mathbb{R}: F_X(x)\leq p\}$, so
		$$F_{X}^{-1}(p)=\mathrm{ln}(1-p)/(-\lambda)+b$$
		
	4. Suppose that $X_1, \cdots,X_n$ are independent copies of $X$ with the unknown parameter $\lambda > 0$.What is the ==maximum likelihood estimate== $\lambda_{MLE}$ for $\lambda$?
		The **likelihood function** is:
		$$\begin{aligned}L(\lambda; X) &=\prod_{i=1}^np_{\lambda}(X_i) \\
		&=\prod_{i=1}^n \lambda e^{-\lambda(X_i-b)}
		\end{aligned}$$
		
		The **log-likelihood function** is:
		$$\begin{aligned}
		&\mathrm{log}L(\lambda;X)=n\mathrm{log} \lambda-\lambda \sum_{i=1}^n (X_i-b) \\
		&\dfrac{\partial}{\partial \lambda}\mathrm{log}L(\lambda;X)=\dfrac{n}{\lambda}-\sum_{i=1}^{n}(X_i-b)
		\end{aligned}$$
		Let $Y=X-b$
		If $\lambda< 1/(\bar{Y}) :=\dfrac{1}{n}\sum_{i=1}^n (Y_i)$, then $\dfrac{\partial}{\partial \lambda}\mathrm{log}L(\lambda)>0$.
		If $\lambda> 1/(\bar{Y}) :=\dfrac{1}{n}\sum_{i=1}^n (Y_i)$, then $\dfrac{\partial}{\partial \lambda}\mathrm{log}L(\lambda)<0$.
		So the maximum likelihood estimate for $\lambda$ is $\hat \lambda_{MLE}=1/\bar{Y}, \: \text{and} \: Y=X-b$.
4. Now download the .csv file entitled “`supermarket data EMATM0061`” from the Assessment section within Blackboard. The .csv file contains synthetic data <font color=#c10b26>on the length of time</font> (in <font color=#c10b26>seconds</font>) taken by a product to get on the shelf again after being sold out. So the sample is <font color=#c10b26>a sequence of time lengths</font>. Let’s model the sequence of time lengths in our sample as independent copies of $X$ with parameter $\lambda$ and known constant $b = 300$ (seconds). Answer the following questions (6) and (7).
	5. Compute and display the <font color=#c10b26>maximum likelihood estimate</font> of $\lambda_{MLE}$ of the parameter $\lambda$.
	```r
		b<-300
		supermarket_data<-read.csv("supermarket_data_EMATM0061.csv")
		#read the data in .csv file
		Supermarket_process<-supermarket_data%>%mutate(Timediff=TimeLength-b) #compute Y=X-b
		lambda_mle<-1/mean(Supermarket_process$Timediff,na.rm=TRUE)
		#compute maximum likelihood estimate
		print(lambda_mle)
	```
		
	```
	[1] 0.01988426
	```
	6. Apply the method of <font color=#c10b26>Bootstrap confidence interval</font> to obtain a <font color=#c10b26>confidence interval</font> for $\lambda$ with a confidence level of 95%. To compute the Bootstrap confidence interval, the number of resamples (i.e., subsamples that are generated to compute the bootstrap statistics) should be **set to 10000**.
		
	```r
	
	library(boot) #load the library
	set.seed(123) #set random seed
	#1. define a function which computes the lambda of a column of interest
	compute_lambda<-function(df,indicies,col_name){
	sub_sample<-slice(df,indicies)%>% pull(all_of(col_name)) #extract subsample
	return(1/mean(sub_sample,na.rm=TRUE)) #reutrn lambda
	}
	#2. use the boot function to generate the bootstrap statistics
	results<-boot(data=Supermarket_process,statistic=compute_lambda,col_name="Timediff",R=10000)
	#3. compute the 95% confidence interval for the lambda
	boot.ci(boot.out = results,type="basic",conf=0.95)
	```
		
	```
	BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
	Based on 10000 bootstrap replicates
	CALL : 
	boot.ci(boot.out = results, conf = 0.95, type = "basic")
	
	Intervals : 
	Level      Basic         
	95%   ( 0.0191,  0.0207 )  
	Calculations and Intervals on Original Scale
	```
		
5. Next, conduct a simulation study to explore the behaviour of the maximum likelihood estimator:
	7. Conduct a <font color=#c10b26>simulation study</font> to explore the behaviour of <font color=#c10b26>the maximum likelihood estimator</font> $\lambda_{MLE}$ for $\lambda$ on simulated data $X_1, \cdots,X_n$ (as independent copies of $X$ with parameter $\lambda$) according to the following instructions. Take $b = 0.01$ and consider a setting in which $\lambda = 2$ and generate a plot of the <font color=#c10b26>mean squared error</font> as a function of the sample size $n$. You should consider a sample size between 100 and 5000 in increments of 10, and consider 100 trials per sample size. For each trial of each sample size generate a random sample $X_1, \cdots,X_n$ (as independent copies of $X$ with parameter $\lambda = 2$), then compute the maximum likelihood estimate $\lambda_{MLE}$ for $\lambda$ based upon the corresponding sample. Display a plot of <font color=#c10b26>the mean square error</font> of $\lambda_{MLE}$ as an estimator for $\lambda$ as a function of the sample size $n$.
	

## B.3
1. Consider a bag of $a$ red balls and $b$ blue balls (so the bag has $a + b$ balls in total), where $a\geq 1$ and $b \geq 1$. We <font color=#c10b26>randomly draw two balls from the bag without replacement</font>. That means, we draw the first ball from the bag and, WITHOUT returning the first ball to the bag, we draw the second one. Each ball has an equal chance of being drawn. Now we <font color=#c10b26>record the colour of the two balls drawn from the bag</font>, and let $X$ denote the number of <font color=#c10b26>red balls minus the number of blue balls</font>. So $X$ is a <font color=#c10b26>discrete random variable</font>. For example, if we draw one red ball and one blue ball, then $X = 0$. Answer the following questions from (1) to (11).
	1. Give a formula for <font color=#c10b26>the probability mass function</font> $p_X : \mathbb{R} \to [0, 1]$ of $X$.
		$$p_X(x)=\begin{cases}
		\dfrac{b(b-1)}{(a+b)(a+b-1)} \quad & \text{if } x=-2 ,\\
		\dfrac{2ab}{(a+b)(a+b-1)} \quad & \text{if } x=0 ,\\
		\dfrac{a(a-1)}{(a+b)(a+b-1)} \quad & \text{if } x=2 ,\\
		0 \quad & \text{otherwise}.
		\end{cases}$$
		
	2. Use the the probability mass function $p_X$ to obtain an expression of the expectation $\mathrm{E}(X)$ of $X$ (i.e., the population mean) in terms of $a$ and $b$.
		$$\begin{aligned}\mathrm{E}(X) &=\sum_{x\in \mathbb{R}}x\cdot p_X(x) \\
		&=-2 \cdot \dfrac{b(b-1)}{(a+b)(a+b-1)}+0 \cdot  \dfrac{2ab}{(a+b)(a+b-1)}+ 2\cdot \dfrac{a(a-1)}{(a+b)(a+b-1)}+\sum_{x\in\mathbb{R}\setminus 0,-2,2 }x\cdot p_X(x) \\
		&= \dfrac{2(a(a-1)-b(b-1))}{(a+b)(a+b-1)} \\
		&=\dfrac{2(a-b)}{(a+b)}
		\end{aligned}$$
		
	3. Give an expression of the variance $\mathrm{Var}(X)$ of $X$ in terms of $a$ and $b$.
		$$\begin{aligned}
		\mathrm{Var}(x) 
		&= \mathrm{E}[(X-\mathrm{E}(X))^2] \\
		&=\sum_{x\in \mathbb{R}}p_X(x)\cdot \left(x-\dfrac{2(a-b)}{(a+b)}\right)^2 \\
		&= \dfrac{b(b-1)}{(a+b)(a+b-1)} \cdot \left(-2-\dfrac{2(a-b)}{(a+b)}\right)^2+\dfrac{2ab}{(a+b)(a+b-1)}\cdot \left(\dfrac{2(a-b)}{(a+b)}\right)^2+\dfrac{a(a-1)}{(a+b)(a+b-1)}\cdot \left(2-\dfrac{2(a-b)}{(a+b)}\right)^2 \\
		&=4-\dfrac{8ab}{(a+b)(a+b-1)}-4\left(\dfrac{a-b}{a+b}\right)^2
		\end{aligned}$$
		
		
	4. Write a function called `compute_expectation_X` that takes $a$ and $b$ as input and outputs the expectation $\mathrm{E}(X)$. Write a function called `compute_variance_X` that takes $a$ and $b$ as input and outputs the variance $\mathrm{Var}(X)$.
	
		```r
		compute_expectation_X<-function(a,b){
		expectation_x<-2*(a-b)/(a+b)
		return(expectation_x)
		}

		compute_variance_X<-function(a,b){
		  variance_x<-4-(8*a*b/((a+b)*(a+b-1)))-4*((a-b)/(a+b))^2
		  return(variance_x)
		}

		print(compute_expectation_X(3,4))
		print(compute_variance_X(3,4))
		```
		
		```
		[1] -0.2857143
		[1] 1.632653
		```
		
2. Additionally, suppose that $X_1,X_2, \cdots,X_n$ are independent copies of $X$. So $X_1,X_2, \cdots,X_n$ are i.i.d. random variables having the same distribution as that of $X$. Let $\bar X=\dfrac{1}{n}\sum_{i=1}^{n}X_i$ sample mean.
	5. Give an expression of the <font color=#c10b26>expectation of the random variable</font> $\bar X$ in terms of $a$, $b$.
		$$\mathrm{E}(\bar X)=\mathrm{E}(\dfrac{1}{n}\sum_{i=1}^{n}X_i)=\dfrac{1}{n}\sum_{i=1}^n \mathrm{E}(X_i)=\dfrac{2(a-b)}{a+b}$$
	6. Give an expression of the variance of the random variable $\bar X$ in terms of $a$, $b$ and $n$.
		$$\mathrm{Var}(\bar X)=\mathrm{Var}(\dfrac{1}{n}\sum_{i=1}^{n}X_i)=\dfrac{1}{n^2}\sum_{i=1}^n \mathrm{Var}(X_i)=\dfrac{4}{n}\left(1-\dfrac{2ab}{(a+b)(a+b-1)}-\left(\dfrac{a-b}{a+b}\right)^2\right)
		$$
		
	7. Create a function called `sample_Xs` which takes as inputs $a$, $b$ and $n$ and outputs a sample $X_1,X_2, \cdots,X_n$ of independent copies of $X$.
		
	```r
	sample_Xs<-function(a,b,n){
	p1<-(b*(b-1))/((a+b)*(a+b-1))
	p2<-(2*a*b)/((a+b)*(a+b-1))
	p3<-(a*(a-1))/((a+b)*(a+b-1))
	return(sample(c(-2,0,2),n,replace=TRUE,prob=c(p1,p2,p3)))
	}
	sample_Xs(3,4,10)
	```
	
	```
	[1] -2  2  0 -2  0 -2 -2  2 -2  2
	```
	
		
	8. Let $a = 3$, $b = 5$ and $n = 100000$. Compute the numerical value of $\mathrm{E}(X)$ using the function `compute_expectation_X` and compute the numerical value of $\mathrm{Var}(X)$ using the function `compute_variance_X`. Then use the function `sample_Xs` to generate a sample $X_1,X_2,\cdots,X_n$ of independent copies of $X$. With the generated sample, compute the sample mean $\bar X$ and sample variance. How close is the sample mean $\bar X$ to $\mathrm{E}(X)$? How close is the sample variance to $\mathrm{Var}(X)$? Explain your observation.
		
	```r
	a<-3
	b<-5
	n<-100000
	Ex<-compute_expectation_X(a,b)  # compute the expectation based on given a,b n
	Varx<-compute_variance_X(a,b) # compute the variance
	Sample_X<-sample_Xs(a,b,n) #generate a sample based on a,b,n
	sample_mean<-mean(Sample_X) # compute the sample mean
	sample_variance<-var(Sample_X) # compute the sample variance
	print(paste("The expectation is:",Ex))
	print(paste("The Variance is:",Varx))
	print(paste("The sample mean is:",sample_mean))
	print(paste("The sample variance is:",sample_variance))
	diff_mu<-abs(sample_mean-Ex) 
	diff_var<-abs(sample_variance-Varx)
	print(paste("The difference value between the population mean(expectation) and sample mean is",diff_mu))
	print(paste("The difference value between the population variance(variance) and sample variance is",diff_var))
	```
		
	```
	[1] "The expectation is: -0.5"
	[1] "The Variance is: 1.60714285714286"[1] "The sample mean is: -0.49998"
	[1] "The sample variance is: 1.61255612516125"
	[1] "The difference value between the population mean(expectation) and sample mean is 2.000000000002e-05"
	[1] "The difference value between the population variance(variance) and sample variance is 0.00541326801839426"
	```
	
	Explain: [[Data Science/R_Projects/My R-note/14 Continuous random variables and limit raws#The law of large numbers|The law of large numbers]] 
		
3. Moreover, let $\mu := \mathrm{E}(X)$ and $\sigma :=\sqrt{\mathrm{Var}(X)/n}$, and let $f_{\mu,\sigma}:\mathbb{R} \to [0,\infty)$ be the <font color=#c10b26>probability density function</font> of a <font color=#c10b26>Gaussian random variable</font> with distribution $\mathcal{N}(\mu,\sigma^2)$, i.e., the expectation is $\mu$ and the variance is $\sigma^2$. Next, conduct a simulation study to explore the behaviour of the sample mean $\bar X$.
	9.  Let $a = 3$, $b = 5$ and $n = 900$. Conduct a simulation study with 20000 trials. In each trial, generate a sample $X_1, \cdots,X_n$ of independent copies of $X$. For each of the 20000 trials, compute the corresponding sample mean $X$ based on $X_1, \cdots,X_n$.
	```r
	num_trials<-20000
	a<-3
	b<-5
	n<-900
	simulation_data<-data.frame(trials=1:num_trials)%>% # generate a column of trials
	  mutate(sample_X=map(.x=trials,.f=~sample_Xs(a,b,n)))%>% #for each trial, generate a sample
	  mutate(sample_mean=map_dbl(.x=sample_X,.f=~mean(.x))) #for each sample, generate a sample mean
	simulation_data%>%head(10)
	```
		
	10. Create <font color=#c10b26>a scatter plot</font> of the points $\{(x_i,f_{\mu,\sigma}(x_i))\}$ where $\{x_i\}$ are a sequence of numbers between $\mu-3\sigma$ and $\mu+3\sigma$ in increments of $0.1\sigma$ . Then append to the scatter plot a curve representing the kernel density of the sample mean $\bar X$ within your simulation study (with 20000 trials). Use different colours for the point $\{(x_i,f_{\mu,\sigma}(x_i))\}$ and the curve in the kernel density plot of the sample mean $\bar X$.
		
	```r
	a<-3
	b<-5
	n<-900
	mu<-compute_expectation_X(a,b) # compute the E(X)
	sigma<-sqrt(compute_variance_X(a,b)/n) # compute the parameter sigma of Gaussian function
	scale_X<-seq(mu-3*sigma,mu+3*sigma,0.1*sigma) # generate a sequence of numbers
	
	scatter_data<-data.frame(scale_X)%>% #generate a data frame including "xi" and corresponding gaussian values
	  mutate(f_xi=dnorm(scale_X,mean=mu,sd=sigma)) # generate the corresponding gaussian values
	
	ggplot()+theme_bw()+ # create a plot
	  # create a scatter plot
	  geom_point(data=scatter_data,aes(x=scale_X,y=f_xi,color="gaussian point"))+
	  # add a curve representing the kernel density of the sample mean
	  geom_density(data=simulation_data,aes(x=sample_mean,color="sample mean"))+
	  #use different colors for the scatter plot and the curve
	  scale_color_manual(name="Legend",values=c("gaussian point"="red","sample mean"="blue"))+
	  labs(x="Sample mean",y="Density")
	```
		
		![[../../../Attachments/Pasted image 20221219223136.png]]
		
	11. Describe the relationship between the density of $\bar X$ and the function $f_{\mu,\sigma}$ displayed in your plot. Try to explain the reason for the observed relationship.
		Explain: [[Data Science/R_Projects/My R-note/14 Continuous random variables and limit raws#The central limit theorem|The central limit theorem]]
		